{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcmkFZiamHPUv43Qt6rKnD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EEGf0Bb9ASC"
      },
      "source": [
        "# 양 방향 RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTpMZN8E9KkX"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC5o4XqT-Guv",
        "outputId": "a8eb11d0-0fb4-4a99-c685-53e1d90a2a26"
      },
      "source": [
        "n_unique_words = 10000\n",
        "maxlen = 200\n",
        "batch_size = 128\n",
        "# 파라미터 num_words는 데이터에서 등장 빈도 순위로 몇 번째에 해당하는 단어까지 사용할지를 의미\n",
        "# 등장 빈도 순위가 1 ~ 10000에 해당하는 단어만 사용\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=n_unique_words)\n",
        "\n",
        "'''\n",
        "전체 훈련 셋에서 각 샘플의 길이는 서로 다를수 있음\n",
        "또한 각 문장은 단어 수가 제 각각\n",
        "모델의 입력으로 사용하려면 모든 샘플 길이를 동일하게 맞추어야함\n",
        "이를 자연어 처리에서는 패딩작업이라고 함, 보통 숫자 0을 넣어서 길이를 맞춤\n",
        "케라스에서는 pad_sequence()를 사용\n",
        "- 첫 번쨰 인자 : 패딩을 진행할 데이터\n",
        "- maxlen : 모든 데이터에 대해 정규화 할 길이\n",
        "'''\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(n_unique_words, 128, input_length=maxlen))\n",
        "\n",
        "# 이부분만 추가하면 양방향 \n",
        "model.add(Bidirectional(LSTM(64))) \n",
        "model.add(Dropout(0.5)) \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=4,\n",
        "          validation_data=[x_test, y_test])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Epoch 1/4\n",
            "196/196 [==============================] - 23s 75ms/step - loss: 0.4295 - accuracy: 0.7917 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/4\n",
            "196/196 [==============================] - 14s 69ms/step - loss: 0.2344 - accuracy: 0.9116 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/4\n",
            "196/196 [==============================] - 13s 68ms/step - loss: 0.1777 - accuracy: 0.9344 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/4\n",
            "196/196 [==============================] - 14s 69ms/step - loss: 0.1464 - accuracy: 0.9465 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1c4cbde5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNFDWH71-K5X",
        "outputId": "5bc8bf56-822b-49ce-f7e6-7270518536ce"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RX3qCGt-OtW",
        "outputId": "41b41d1b-be2e-4377-86d7-380627c8c45a"
      },
      "source": [
        "loss, acc = model.evaluate(x_train, y_train, batch_size=384, verbose=1)\n",
        "print('Training accuracy', model.metrics_names, acc)\n",
        "print('Training accuracy', model.metrics_names, loss)\n",
        "loss, acc = model.evaluate(x_test, y_test, batch_size=384, verbose=1)\n",
        "print('Testing accuracy', model.metrics_names, acc)\n",
        "print('Testing accuracy', model.metrics_names, loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66/66 [==============================] - 3s 34ms/step - loss: 0.0887 - accuracy: 0.9730\n",
            "Training accuracy ['loss', 'accuracy'] 0.9729599952697754\n",
            "Training accuracy ['loss', 'accuracy'] 0.08874548971652985\n",
            "66/66 [==============================] - 2s 34ms/step - loss: 0.3695 - accuracy: 0.8640\n",
            "Testing accuracy ['loss', 'accuracy'] 0.8640400171279907\n",
            "Testing accuracy ['loss', 'accuracy'] 0.3694588541984558\n"
          ]
        }
      ]
    }
  ]
}
