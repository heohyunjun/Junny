{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxY3HzO7kbAMH93vujgb5x"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQYD7fN4KUpK"
      },
      "source": [
        "## 심층신경망을 이용한 XOR (텐서플로 1.x)\n",
        "- 206 ~ 216"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imEcyMpVMx2t",
        "outputId": "f884d231-f35c-4d16-b206-a9ee112da7e4"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUKqythKMx2t"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pEoUm12_Mx2u",
        "outputId": "1a68b3f5-2589-435b-f153-30420067cd18"
      },
      "source": [
        "tf.enable_eager_execution()\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9oBSv__Mx2u"
      },
      "source": [
        "# X\n",
        "X = np.array([\n",
        "              [0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]\n",
        "], dtype = 'float32')\n",
        "\n",
        "# y\n",
        "y = np.array([\n",
        "              [0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]\n",
        "],dtype = 'float32')\n",
        "\n",
        "# w0\n",
        "w0 = tf.Variable([\n",
        "                  [1, 2],\n",
        "                  [3, 4]\n",
        "] , dtype=\"float32\")\n",
        "\n",
        "# w1\n",
        "w1 = tf.Variable([\n",
        "                  [5],\n",
        "                  [6]\n",
        "], dtype=\"float32\")\n",
        "\n",
        "# b0\n",
        "b0 = tf.Variable([\n",
        "                  [0, 0]\n",
        "], dtype = 'float32')\n",
        "\n",
        "# b1\n",
        "b1 = tf.Variable([\n",
        "                  [0]\n",
        "], dtype=\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPracvNHM8Py",
        "outputId": "58a5dba0-323d-4d9d-e815-cde1054302e0"
      },
      "source": [
        "# 첫번쨰\n",
        "hypothesis0 = tf.sigmoid(tf.matmul(X , w0) + b0)\n",
        "print(\"hypothesis0_sigmoid :\\n\",hypothesis0)\n",
        "print(\"=\"* 50)\n",
        "\n",
        "# 두번쨰\n",
        "hypothesis1 = tf.sigmoid(tf.matmul(hypothesis0, w1) + b1)\n",
        "print(\"hypothesis1_sigmoid :\\n\",hypothesis1)\n",
        "print(\"=\"* 50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hypothesis0_sigmoid :\n",
            " tf.Tensor(\n",
            "[[0.5        0.5       ]\n",
            " [0.95257413 0.98201376]\n",
            " [0.7310586  0.8807971 ]\n",
            " [0.98201376 0.99752736]], shape=(4, 2), dtype=float32)\n",
            "==================================================\n",
            "hypothesis1_sigmoid :\n",
            " tf.Tensor(\n",
            "[[0.9959299]\n",
            " [0.9999764]\n",
            " [0.999869 ]\n",
            " [0.9999814]], shape=(4, 1), dtype=float32)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuwgyhWwNVLb",
        "outputId": "6b11f9a0-a31e-4edb-b9fb-ce1816b566d0"
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(0.1)\n",
        "for step in range(5000):\n",
        "  with tf.GradientTape() as tape:\n",
        "    hypothesis0 = tf.sigmoid(tf.matmul(X, w0) +b0)\n",
        "\n",
        "    hypothesis1 = tf.sigmoid(tf.matmul(hypothesis0, w1) + b1)\n",
        "\n",
        "    cost = -tf.reduce_mean(y * tf.log(hypothesis1) + (1-y) * tf.log(1- hypothesis1))\n",
        "\n",
        "    grads = tape.gradient(cost, [w0, w1, b0, b1])\n",
        "\n",
        "    optimizer.apply_gradients(grads_and_vars = zip(grads,[w0, w1, b0, b1]))\n",
        "    if step % 100 == 0:\n",
        "      print(\"cost :{}, w0:{}, w1 : {}\".format(cost, w0, w1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost :4.0991926193237305, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[0.9000014, 1.9000086],\n",
            "       [2.9000015, 3.9000084]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[4.9],\n",
            "       [5.9]], dtype=float32)>\n",
            "cost :0.557486355304718, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-2.0565379, -4.4126105],\n",
            "       [ 1.2810545,  3.0600321]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[2.6855311],\n",
            "       [3.8502126]], dtype=float32)>\n",
            "cost :0.5103297233581543, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-2.586327 , -6.2746325],\n",
            "       [ 1.5904139,  4.8805475]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[2.3543897],\n",
            "       [4.411695 ]], dtype=float32)>\n",
            "cost :0.49529534578323364, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-2.8877606, -7.3770695],\n",
            "       [ 1.6697845,  5.898697 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[2.0767365],\n",
            "       [4.9937453]], dtype=float32)>\n",
            "cost :0.48861074447631836, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-3.0569203, -8.128932 ],\n",
            "       [ 1.6668217,  6.5931687]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[1.8414878],\n",
            "       [5.475655 ]], dtype=float32)>\n",
            "cost :0.485080361366272, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-3.160711 , -8.691832 ],\n",
            "       [ 1.6366962,  7.1160574]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[1.6368624],\n",
            "       [5.8694105]], dtype=float32)>\n",
            "cost :0.48299354314804077, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-3.2296495, -9.139407 ],\n",
            "       [ 1.6007798,  7.53476  ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[1.4542738],\n",
            "       [6.1975965]], dtype=float32)>\n",
            "cost :0.48165521025657654, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-3.2783184, -9.510465 ],\n",
            "       [ 1.5663005,  7.8843317]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[1.2874048],\n",
            "       [6.477645 ]], dtype=float32)>\n",
            "cost :0.4807426333427429, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-3.314224 , -9.82756  ],\n",
            "       [ 1.5354035,  8.185008 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[1.1316679],\n",
            "       [6.721667 ]], dtype=float32)>\n",
            "cost :0.48008978366851807, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.3415287, -10.104808 ],\n",
            "       [  1.5085064,   8.449392 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[0.9836686],\n",
            "       [6.9380364]], dtype=float32)>\n",
            "cost :0.4796045422554016, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.3626783, -10.351541 ],\n",
            "       [  1.4854835,   8.685834 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[0.8407926],\n",
            "       [7.1326537]], dtype=float32)>\n",
            "cost :0.4792320132255554, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.379184 , -10.574234 ],\n",
            "       [  1.4660876,   8.900144 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[0.7009053],\n",
            "       [7.30979  ]], dtype=float32)>\n",
            "cost :0.47893819212913513, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.391991 , -10.777535 ],\n",
            "       [  1.4501035,   9.096503 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[0.5621473],\n",
            "       [7.4726124]], dtype=float32)>\n",
            "cost :0.4787004590034485, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.401685 , -10.964891 ],\n",
            "       [  1.4374093,   9.278034 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[0.42276862],\n",
            "       [7.623529  ]], dtype=float32)>\n",
            "cost :0.47850340604782104, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.4085913, -11.138975 ],\n",
            "       [  1.4280113,   9.447134 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[0.28098127],\n",
            "       [7.764416  ]], dtype=float32)>\n",
            "cost :0.4783359169960022, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.4128196, -11.301791 ],\n",
            "       [  1.4220831,   9.605665 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[0.13479872],\n",
            "       [7.8967476 ]], dtype=float32)>\n",
            "cost :0.4781891107559204, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.4142544, -11.454964 ],\n",
            "       [  1.4200283,   9.755134 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-0.01817416],\n",
            "       [ 8.021718  ]], dtype=float32)>\n",
            "cost :0.4780554473400116, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.4124904, -11.599762 ],\n",
            "       [  1.4226123,   9.896752 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-0.18107073],\n",
            "       [ 8.140307  ]], dtype=float32)>\n",
            "cost :0.4779266119003296, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.4066567, -11.737311 ],\n",
            "       [  1.4312202,  10.031512 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-0.35834673],\n",
            "       [ 8.25334   ]], dtype=float32)>\n",
            "cost :0.4777912497520447, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.3949845, -11.868483 ],\n",
            "       [  1.4484581,  10.160298 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-0.5569558],\n",
            "       [ 8.3615265]], dtype=float32)>\n",
            "cost :0.47762706875801086, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.3736005, -11.994039 ],\n",
            "       [  1.4797406,  10.28391  ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-0.7891075],\n",
            "       [ 8.465539 ]], dtype=float32)>\n",
            "cost :0.47737276554107666, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.332303 , -12.114664 ],\n",
            "       [  1.5386678,  10.403223 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-1.0802407],\n",
            "       [ 8.566114 ]], dtype=float32)>\n",
            "cost :0.47673386335372925, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -3.2307463, -12.231041 ],\n",
            "       [  1.6757313,  10.519877 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-1.5027233],\n",
            "       [ 8.664621 ]], dtype=float32)>\n",
            "cost :0.4456459581851959, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -1.9512024, -12.344152 ],\n",
            "       [  3.0577855,  10.65517  ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-2.7257624],\n",
            "       [ 8.776811 ]], dtype=float32)>\n",
            "cost :0.009364759549498558, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -7.283764, -12.369929],\n",
            "       [  7.598863,  11.797087]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-9.525101],\n",
            "       [10.312774]], dtype=float32)>\n",
            "cost :0.005068529862910509, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -7.6133637, -12.385313 ],\n",
            "       [  8.024998 ,  12.112951 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-10.758629],\n",
            "       [ 11.394821]], dtype=float32)>\n",
            "cost :0.00344579154625535, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -7.8172436, -12.400163 ],\n",
            "       [  8.26799  ,  12.267687 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-11.524881],\n",
            "       [ 12.113351]], dtype=float32)>\n",
            "cost :0.002581524197012186, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -7.9666147, -12.414173 ],\n",
            "       [  8.440047 ,  12.368521 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-12.096564],\n",
            "       [ 12.661172]], dtype=float32)>\n",
            "cost :0.00204339437186718, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.085327, -12.427436],\n",
            "       [  8.573954,  12.442609]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-12.558727],\n",
            "       [ 13.109098]], dtype=float32)>\n",
            "cost :0.0016759838908910751, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.1843405, -12.440071 ],\n",
            "       [  8.684059 ,  12.5008955]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-12.950297],\n",
            "       [ 13.491286]], dtype=float32)>\n",
            "cost :0.0014093072386458516, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.269626, -12.452183],\n",
            "       [  8.777925,  12.548817]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-13.29248 ],\n",
            "       [ 13.826882]], dtype=float32)>\n",
            "cost :0.0012071061646565795, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.344806, -12.463851],\n",
            "       [  8.86002 ,  12.589465]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-13.59817 ],\n",
            "       [ 14.127727]], dtype=float32)>\n",
            "cost :0.0010487193940207362, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.412245, -12.475148],\n",
            "       [  8.933197,  12.624749]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-13.875786],\n",
            "       [ 14.401662]], dtype=float32)>\n",
            "cost :0.000921460276003927, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.473571, -12.486128],\n",
            "       [  8.999397,  12.655919]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-14.131142],\n",
            "       [ 14.654155]], dtype=float32)>\n",
            "cost :0.0008170527289621532, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.529945, -12.496829],\n",
            "       [  9.059988,  12.683849]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-14.368431],\n",
            "       [ 14.889172]], dtype=float32)>\n",
            "cost :0.0007300307042896748, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.582232 , -12.5072975],\n",
            "       [  9.115983 ,  12.709166 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-14.590772],\n",
            "       [ 15.109674]], dtype=float32)>\n",
            "cost :0.0006564079085364938, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.63109 , -12.517556],\n",
            "       [  9.16814 ,  12.732331]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-14.800545],\n",
            "       [ 15.317955]], dtype=float32)>\n",
            "cost :0.0005934223881922662, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.6770315, -12.527628 ],\n",
            "       [  9.217048 ,  12.7537   ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-14.999621 ],\n",
            "       [ 15.5157995]], dtype=float32)>\n",
            "cost :0.0005390143487602472, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.720462, -12.537541],\n",
            "       [  9.263175,  12.773545]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-15.189484],\n",
            "       [ 15.704645]], dtype=float32)>\n",
            "cost :0.0004915721947327256, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.761711 , -12.547315 ],\n",
            "       [  9.30689  ,  12.7920885]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-15.371334],\n",
            "       [ 15.885657]], dtype=float32)>\n",
            "cost :0.0004499168717302382, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.80105 , -12.556969],\n",
            "       [  9.348496,  12.809499]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-15.54617],\n",
            "       [ 16.05979]], dtype=float32)>\n",
            "cost :0.00041307875653728843, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.8386965, -12.566505 ],\n",
            "       [  9.388246 ,  12.825926 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-15.7148  ],\n",
            "       [ 16.227854]], dtype=float32)>\n",
            "cost :0.0003803118015639484, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.874843, -12.575944],\n",
            "       [  9.426349,  12.841479]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-15.877941],\n",
            "       [ 16.390501]], dtype=float32)>\n",
            "cost :0.000351034221239388, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.909645, -12.58529 ],\n",
            "       [  9.462977,  12.856264]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-16.036171],\n",
            "       [ 16.548313]], dtype=float32)>\n",
            "cost :0.0003247687127441168, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.943237, -12.594552],\n",
            "       [  9.498285,  12.870363]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-16.189964],\n",
            "       [ 16.701803]], dtype=float32)>\n",
            "cost :0.0003010081418324262, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -8.975734, -12.60375 ],\n",
            "       [  9.532402,  12.883842]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-16.339794],\n",
            "       [ 16.851376]], dtype=float32)>\n",
            "cost :0.00027954368852078915, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -9.00724  , -12.6129055],\n",
            "       [  9.565435 ,  12.896767 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-16.486025],\n",
            "       [ 16.997389]], dtype=float32)>\n",
            "cost :0.0002599876024760306, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -9.037835, -12.621967],\n",
            "       [  9.597484,  12.909187]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-16.62899 ],\n",
            "       [ 17.140177]], dtype=float32)>\n",
            "cost :0.0002422205579932779, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -9.067604 , -12.6310215],\n",
            "       [  9.628632 ,  12.921149 ]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-16.768972],\n",
            "       [ 17.28002 ]], dtype=float32)>\n",
            "cost :0.00022598904615733773, w0:<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -9.096615 , -12.639986 ],\n",
            "       [  9.658953 ,  12.9326935]], dtype=float32)>, w1 : <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-16.906229],\n",
            "       [ 17.417168]], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJynbn3nOMgv",
        "outputId": "ac9be5ea-16d2-4e1a-8b7b-3b030ed42bea"
      },
      "source": [
        "# 가중치, 편향 출력\n",
        "print(\"w0 : \\n\",w0)\n",
        "print(\"w1 : \\n\",w1)\n",
        "\n",
        "print(\"b0 : \\n\",b0)\n",
        "print(\"b10 : \\n\",b1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w0 : \n",
            " <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[ -9.12464 , -12.648861],\n",
            "       [  9.688222,  12.943744]], dtype=float32)>\n",
            "w1 : \n",
            " <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
            "array([[-17.039652],\n",
            "       [ 17.550508]], dtype=float32)>\n",
            "b0 : \n",
            " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[ 4.284906 , -7.1995845]], dtype=float32)>\n",
            "b10 : \n",
            " <tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, numpy=array([[8.180049]], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csQzAQuiObkv",
        "outputId": "d58b62cb-c424-4ace-de80-7dae3a1c42af"
      },
      "source": [
        "# 예측\n",
        "# 첫번쨰 선형회귀\n",
        "hypothesis0 = tf.sigmoid(tf.matmul(X, w0) + b0)\n",
        "\n",
        "# 2번쨰 선형회귀값을 예측값으로\n",
        "predict = tf.sigmoid(tf.matmul(hypothesis0, w1) +b1)\n",
        "\n",
        "print(\"predict = \\n\",predict)\n",
        "print(\"=\"*  100)\n",
        "\n",
        "predict01 = tf.cast(predict>0.5, dtype = tf.float32)\n",
        "print(\"0.5이상이면 1, 아니면 0 으로 변환 : \\n\", predict01)\n",
        "print(\"=\"*  100)\n",
        "\n",
        "# 정답이랑 비교\n",
        "ac01 = tf.equal(predict01, y)\n",
        "print(\"정답이면 True, 아니면 False :\\n\", ac01)\n",
        "print(\"=\"*  100)\n",
        "\n",
        "# True,False  ->1,0\n",
        "ac02 = tf.cast(ac01, dtype = tf.float32)\n",
        "print(\"True, False -> 1,0으로 변환 :\\n\",ac02)\n",
        "print(\"=\"*  100)\n",
        "\n",
        "# 정확도 구하기 \n",
        "ac03 = tf.reduce_mean(ac02)\n",
        "print(\"정확도:\",ac03.numpy())\n",
        "print(\"=\"*  100)\n",
        "\n",
        "# 위에 과정을 한줄로\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predict01, y), dtype = tf.float32))\n",
        "print(\"정확도 :\",accuracy.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict = \n",
            " tf.Tensor(\n",
            "[[1.8133664e-04]\n",
            " [9.9982232e-01]\n",
            " [9.9967980e-01]\n",
            " [1.6499007e-04]], shape=(4, 1), dtype=float32)\n",
            "====================================================================================================\n",
            "0.5이상이면 1, 아니면 0 으로 변환 : \n",
            " tf.Tensor(\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]], shape=(4, 1), dtype=float32)\n",
            "====================================================================================================\n",
            "정답이면 True, 아니면 False :\n",
            " tf.Tensor(\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]], shape=(4, 1), dtype=bool)\n",
            "====================================================================================================\n",
            "True, False -> 1,0으로 변환 :\n",
            " tf.Tensor(\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]], shape=(4, 1), dtype=float32)\n",
            "====================================================================================================\n",
            "정확도: 1.0\n",
            "====================================================================================================\n",
            "정확도 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DGEaB28Qb8A",
        "outputId": "54a8e9c5-2eff-444d-82f6-e13c46b10e50"
      },
      "source": [
        "# 0, 1 XOR 연산\n",
        "arr = np.array([\n",
        "                [0,1]\n",
        "], dtype = \"float32\")\n",
        "\n",
        "hypothesis0 =tf.sigmoid(tf.matmul(arr, w0) + b0)\n",
        "\n",
        "predict = tf.sigmoid(tf.matmul(hypothesis0, w1) + b1)\n",
        "\n",
        "print(predict.numpy())\n",
        "\n",
        "predict = tf.cast(predict > 0.5,1, 0)\n",
        "print(predict.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9998223]]\n",
            "[[1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJMbYSpqRA33",
        "outputId": "d6784877-8aa1-442c-a1fe-596b9f5eb11e"
      },
      "source": [
        "# 1, 1 XOR 연산\n",
        "arr = np.array([\n",
        "                [1,1]\n",
        "], dtype = \"float32\")\n",
        "\n",
        "hypothesis0 =tf.sigmoid(tf.matmul(arr, w0) + b0)\n",
        "\n",
        "predict = tf.sigmoid(tf.matmul(hypothesis0, w1) + b1)\n",
        "\n",
        "print(predict.numpy())\n",
        "\n",
        "predict = tf.cast(predict > 0.5,1, 0)\n",
        "print(predict.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00016499]]\n",
            "[[0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaL4mKnjKZmI"
      },
      "source": [
        "## 심층신경망을 이용한 XOR (텐서플로 2.x)\n",
        "\n",
        "- 217 ~ 227"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXLK_pn3RH4f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oI8_MCK7RX57",
        "outputId": "530d70b3-142f-43c5-aa85-b992d5f51488"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ufl9mJRf27"
      },
      "source": [
        "# X\n",
        "X = np.array([\n",
        "              [0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]\n",
        "], dtype = 'float32')\n",
        "\n",
        "# y\n",
        "y = np.array(\n",
        "              [0, 1, 1, 0]\n",
        ",dtype = 'float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHWkEYCRRs4a",
        "outputId": "1b4cb1da-b5a3-4364-8ed2-620d623cea71"
      },
      "source": [
        "model =  Sequential()\n",
        "\n",
        "# 출력 데이터는 hypothesis0이고 칸의 수는 2\n",
        "# input_dim =2 , 입력데이터는 X이고 칸의 수는 2\n",
        "model.add(Dense(2, input_dim = 2, activation = \"sigmoid\"))\n",
        "\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# binary_crossentropy =\n",
        "# -1/4 * (y * np.log(hypothesis) + (1-y) * np.log(1-hypothesis))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate = 0.01), metrics=['acc'])\n",
        "\n",
        "model.fit(X, y, epochs = 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.7197 - acc: 0.5000\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7168 - acc: 0.5000\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7141 - acc: 0.5000\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7115 - acc: 0.5000\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7091 - acc: 0.5000\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7068 - acc: 0.5000\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7047 - acc: 0.5000\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7027 - acc: 0.5000\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7009 - acc: 0.5000\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6992 - acc: 0.5000\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6977 - acc: 0.5000\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.5000\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6951 - acc: 0.5000\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6939 - acc: 0.5000\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6929 - acc: 0.5000\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6920 - acc: 0.5000\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6912 - acc: 0.5000\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6905 - acc: 0.5000\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6899 - acc: 0.5000\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6893 - acc: 0.2500\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6888 - acc: 0.2500\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6884 - acc: 0.2500\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6881 - acc: 0.2500\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6878 - acc: 0.2500\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6875 - acc: 0.2500\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6873 - acc: 0.5000\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6871 - acc: 0.5000\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6870 - acc: 0.5000\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6868 - acc: 0.5000\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6867 - acc: 0.5000\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6866 - acc: 0.5000\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6865 - acc: 0.7500\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6864 - acc: 0.7500\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6862 - acc: 0.7500\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6861 - acc: 0.7500\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6860 - acc: 0.7500\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6859 - acc: 0.7500\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6858 - acc: 0.7500\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6856 - acc: 0.7500\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6855 - acc: 0.7500\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6853 - acc: 0.7500\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6852 - acc: 0.7500\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6850 - acc: 0.7500\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6848 - acc: 0.7500\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6846 - acc: 0.7500\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6844 - acc: 0.7500\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6842 - acc: 0.7500\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6840 - acc: 0.7500\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6838 - acc: 0.7500\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6836 - acc: 0.7500\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6834 - acc: 0.7500\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6831 - acc: 0.7500\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6829 - acc: 0.7500\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6827 - acc: 0.7500\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6824 - acc: 0.7500\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6822 - acc: 0.7500\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6819 - acc: 0.7500\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6817 - acc: 0.7500\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6814 - acc: 0.7500\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6812 - acc: 0.7500\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6809 - acc: 0.7500\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6806 - acc: 0.7500\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6803 - acc: 0.7500\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6801 - acc: 0.7500\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6798 - acc: 0.7500\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6795 - acc: 0.7500\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6792 - acc: 0.7500\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6789 - acc: 0.5000\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6786 - acc: 0.5000\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6783 - acc: 0.5000\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6780 - acc: 0.5000\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6777 - acc: 0.5000\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6773 - acc: 0.5000\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6770 - acc: 0.5000\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6767 - acc: 0.5000\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6763 - acc: 0.5000\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6760 - acc: 0.5000\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6756 - acc: 0.5000\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6753 - acc: 0.5000\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6749 - acc: 0.5000\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6745 - acc: 0.5000\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6741 - acc: 0.7500\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6737 - acc: 0.7500\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6734 - acc: 0.7500\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6730 - acc: 0.7500\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6726 - acc: 0.7500\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6721 - acc: 0.7500\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6717 - acc: 0.7500\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.7500\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.7500\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6704 - acc: 0.7500\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6700 - acc: 0.7500\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6696 - acc: 0.7500\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6691 - acc: 0.7500\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6686 - acc: 0.7500\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6682 - acc: 0.7500\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6677 - acc: 0.7500\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6672 - acc: 0.7500\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6667 - acc: 0.7500\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6662 - acc: 0.7500\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6658 - acc: 0.7500\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6652 - acc: 0.7500\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6647 - acc: 0.7500\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6642 - acc: 0.7500\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6637 - acc: 0.7500\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6632 - acc: 0.7500\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6626 - acc: 0.7500\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6621 - acc: 0.7500\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6615 - acc: 0.7500\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6610 - acc: 0.7500\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6604 - acc: 0.7500\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6598 - acc: 0.7500\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6593 - acc: 0.7500\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6587 - acc: 0.7500\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6581 - acc: 0.7500\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6575 - acc: 0.7500\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6569 - acc: 0.7500\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6563 - acc: 0.7500\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6557 - acc: 0.7500\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6550 - acc: 0.7500\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6544 - acc: 0.7500\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6538 - acc: 0.7500\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6531 - acc: 0.7500\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6525 - acc: 0.7500\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6518 - acc: 0.7500\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6511 - acc: 0.7500\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6505 - acc: 0.7500\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6498 - acc: 0.7500\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6491 - acc: 0.7500\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6484 - acc: 0.7500\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6477 - acc: 0.7500\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6471 - acc: 0.7500\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6463 - acc: 0.7500\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6456 - acc: 0.7500\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6449 - acc: 0.7500\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6442 - acc: 0.7500\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6435 - acc: 0.7500\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6428 - acc: 0.7500\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6420 - acc: 0.7500\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6413 - acc: 0.7500\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6405 - acc: 0.7500\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6398 - acc: 0.7500\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6390 - acc: 0.7500\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6383 - acc: 0.7500\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6375 - acc: 0.7500\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6368 - acc: 0.7500\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6360 - acc: 0.7500\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6352 - acc: 0.7500\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6344 - acc: 0.7500\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6337 - acc: 0.7500\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6329 - acc: 0.7500\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6321 - acc: 0.7500\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6313 - acc: 0.7500\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6305 - acc: 0.7500\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6297 - acc: 0.7500\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6289 - acc: 0.7500\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6281 - acc: 0.7500\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6273 - acc: 0.7500\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6265 - acc: 0.7500\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6257 - acc: 0.7500\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6249 - acc: 0.7500\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6241 - acc: 0.7500\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6233 - acc: 0.7500\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6225 - acc: 0.7500\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6217 - acc: 0.7500\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6209 - acc: 0.7500\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6201 - acc: 0.7500\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6193 - acc: 0.7500\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6184 - acc: 0.7500\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6176 - acc: 0.7500\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6168 - acc: 0.7500\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6160 - acc: 0.7500\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6152 - acc: 0.7500\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6144 - acc: 0.7500\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6135 - acc: 0.7500\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6127 - acc: 0.7500\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6119 - acc: 0.7500\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6111 - acc: 0.7500\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6103 - acc: 0.7500\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6095 - acc: 0.7500\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6086 - acc: 0.7500\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6078 - acc: 0.7500\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6070 - acc: 0.7500\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6062 - acc: 0.7500\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6054 - acc: 0.7500\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6046 - acc: 0.7500\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6037 - acc: 0.7500\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6029 - acc: 0.7500\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6021 - acc: 0.7500\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6013 - acc: 0.7500\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6005 - acc: 0.7500\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5997 - acc: 0.7500\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5989 - acc: 0.7500\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5981 - acc: 0.7500\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5973 - acc: 0.7500\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5965 - acc: 0.7500\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5957 - acc: 0.7500\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5948 - acc: 0.7500\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5940 - acc: 0.7500\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5932 - acc: 0.7500\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5924 - acc: 0.7500\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5916 - acc: 0.7500\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5908 - acc: 0.7500\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5900 - acc: 0.7500\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5892 - acc: 0.7500\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5884 - acc: 0.7500\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5876 - acc: 0.7500\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5868 - acc: 0.7500\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5860 - acc: 0.7500\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5852 - acc: 0.7500\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5844 - acc: 0.7500\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5836 - acc: 0.7500\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5828 - acc: 0.7500\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5820 - acc: 0.7500\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5812 - acc: 0.7500\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5804 - acc: 0.7500\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5796 - acc: 0.7500\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5788 - acc: 0.7500\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5780 - acc: 0.7500\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5772 - acc: 0.7500\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5764 - acc: 0.7500\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5756 - acc: 0.7500\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5748 - acc: 0.7500\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5740 - acc: 0.7500\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5732 - acc: 0.7500\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5724 - acc: 0.7500\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5716 - acc: 0.7500\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5708 - acc: 0.7500\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5699 - acc: 0.7500\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5691 - acc: 0.7500\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5683 - acc: 0.7500\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5675 - acc: 0.7500\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5666 - acc: 0.7500\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5658 - acc: 0.7500\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5649 - acc: 0.7500\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5641 - acc: 0.7500\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5632 - acc: 0.7500\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5624 - acc: 0.7500\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5615 - acc: 0.7500\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5606 - acc: 0.7500\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5597 - acc: 0.7500\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5588 - acc: 0.7500\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5580 - acc: 0.7500\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5570 - acc: 0.7500\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5561 - acc: 0.7500\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5552 - acc: 0.7500\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5543 - acc: 0.7500\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5533 - acc: 0.7500\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5524 - acc: 0.7500\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5514 - acc: 0.7500\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5504 - acc: 0.7500\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5494 - acc: 0.7500\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5484 - acc: 0.7500\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5474 - acc: 0.7500\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5464 - acc: 0.7500\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5453 - acc: 0.7500\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5443 - acc: 0.7500\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5432 - acc: 0.7500\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5421 - acc: 0.7500\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5410 - acc: 0.7500\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5399 - acc: 0.7500\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5387 - acc: 0.7500\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5376 - acc: 0.7500\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5364 - acc: 0.7500\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5352 - acc: 0.7500\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5340 - acc: 0.7500\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5327 - acc: 0.7500\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5315 - acc: 0.7500\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5302 - acc: 0.7500\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5289 - acc: 0.7500\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5275 - acc: 0.7500\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5262 - acc: 0.7500\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5248 - acc: 0.7500\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5234 - acc: 0.7500\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5220 - acc: 0.7500\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5205 - acc: 0.7500\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5191 - acc: 0.7500\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5176 - acc: 0.7500\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5160 - acc: 0.7500\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5145 - acc: 0.7500\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5129 - acc: 0.7500\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5113 - acc: 0.7500\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5097 - acc: 0.7500\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5080 - acc: 0.7500\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5063 - acc: 0.7500\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5046 - acc: 0.7500\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5029 - acc: 0.7500\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5011 - acc: 0.7500\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4994 - acc: 0.7500\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4975 - acc: 0.7500\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4957 - acc: 0.7500\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4938 - acc: 0.7500\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4920 - acc: 0.7500\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4901 - acc: 0.7500\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4881 - acc: 0.7500\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4862 - acc: 0.7500\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4842 - acc: 0.7500\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.4822 - acc: 0.7500\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4802 - acc: 0.7500\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4781 - acc: 0.7500\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4761 - acc: 0.7500\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4740 - acc: 0.7500\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4719 - acc: 0.7500\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4698 - acc: 0.7500\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4677 - acc: 0.7500\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4655 - acc: 0.7500\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4633 - acc: 0.7500\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4612 - acc: 0.7500\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4590 - acc: 0.7500\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4568 - acc: 0.7500\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4545 - acc: 0.7500\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4523 - acc: 0.7500\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4500 - acc: 0.7500\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4478 - acc: 0.7500\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4455 - acc: 1.0000\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4432 - acc: 1.0000\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4409 - acc: 1.0000\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4386 - acc: 1.0000\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4363 - acc: 1.0000\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4339 - acc: 1.0000\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4316 - acc: 1.0000\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4293 - acc: 1.0000\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4269 - acc: 1.0000\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4245 - acc: 1.0000\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4222 - acc: 1.0000\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4198 - acc: 1.0000\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4175 - acc: 1.0000\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4151 - acc: 1.0000\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4127 - acc: 1.0000\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4103 - acc: 1.0000\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4080 - acc: 1.0000\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4056 - acc: 1.0000\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4032 - acc: 1.0000\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4008 - acc: 1.0000\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3984 - acc: 1.0000\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3961 - acc: 1.0000\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3937 - acc: 1.0000\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3913 - acc: 1.0000\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3889 - acc: 1.0000\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3866 - acc: 1.0000\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3842 - acc: 1.0000\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3818 - acc: 1.0000\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3795 - acc: 1.0000\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3771 - acc: 1.0000\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3748 - acc: 1.0000\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3725 - acc: 1.0000\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3701 - acc: 1.0000\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3678 - acc: 1.0000\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3655 - acc: 1.0000\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3632 - acc: 1.0000\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3609 - acc: 1.0000\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3586 - acc: 1.0000\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3563 - acc: 1.0000\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3540 - acc: 1.0000\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3518 - acc: 1.0000\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3495 - acc: 1.0000\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3473 - acc: 1.0000\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3450 - acc: 1.0000\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3428 - acc: 1.0000\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3406 - acc: 1.0000\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3384 - acc: 1.0000\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3362 - acc: 1.0000\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3340 - acc: 1.0000\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3318 - acc: 1.0000\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3297 - acc: 1.0000\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3275 - acc: 1.0000\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3254 - acc: 1.0000\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3233 - acc: 1.0000\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3212 - acc: 1.0000\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3191 - acc: 1.0000\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3170 - acc: 1.0000\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3149 - acc: 1.0000\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3129 - acc: 1.0000\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3108 - acc: 1.0000\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3088 - acc: 1.0000\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3068 - acc: 1.0000\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3048 - acc: 1.0000\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3028 - acc: 1.0000\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3008 - acc: 1.0000\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2988 - acc: 1.0000\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2969 - acc: 1.0000\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2949 - acc: 1.0000\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2930 - acc: 1.0000\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2911 - acc: 1.0000\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2892 - acc: 1.0000\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2873 - acc: 1.0000\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2854 - acc: 1.0000\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2836 - acc: 1.0000\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2817 - acc: 1.0000\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2799 - acc: 1.0000\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2781 - acc: 1.0000\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2763 - acc: 1.0000\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2745 - acc: 1.0000\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2727 - acc: 1.0000\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2710 - acc: 1.0000\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2692 - acc: 1.0000\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2675 - acc: 1.0000\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2658 - acc: 1.0000\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2641 - acc: 1.0000\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2624 - acc: 1.0000\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2607 - acc: 1.0000\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2590 - acc: 1.0000\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2574 - acc: 1.0000\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2557 - acc: 1.0000\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2541 - acc: 1.0000\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2525 - acc: 1.0000\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2509 - acc: 1.0000\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2493 - acc: 1.0000\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2477 - acc: 1.0000\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2462 - acc: 1.0000\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2446 - acc: 1.0000\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2431 - acc: 1.0000\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2416 - acc: 1.0000\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2401 - acc: 1.0000\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2386 - acc: 1.0000\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2371 - acc: 1.0000\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2356 - acc: 1.0000\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2341 - acc: 1.0000\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2327 - acc: 1.0000\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2313 - acc: 1.0000\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2298 - acc: 1.0000\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2284 - acc: 1.0000\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2270 - acc: 1.0000\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2256 - acc: 1.0000\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2242 - acc: 1.0000\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2229 - acc: 1.0000\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2215 - acc: 1.0000\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2202 - acc: 1.0000\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2188 - acc: 1.0000\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2175 - acc: 1.0000\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2162 - acc: 1.0000\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2149 - acc: 1.0000\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2136 - acc: 1.0000\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2124 - acc: 1.0000\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2111 - acc: 1.0000\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2098 - acc: 1.0000\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2086 - acc: 1.0000\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2074 - acc: 1.0000\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2061 - acc: 1.0000\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2049 - acc: 1.0000\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2037 - acc: 1.0000\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2025 - acc: 1.0000\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2013 - acc: 1.0000\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2002 - acc: 1.0000\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1990 - acc: 1.0000\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1979 - acc: 1.0000\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1967 - acc: 1.0000\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1956 - acc: 1.0000\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1945 - acc: 1.0000\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1933 - acc: 1.0000\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1922 - acc: 1.0000\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1911 - acc: 1.0000\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1901 - acc: 1.0000\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1890 - acc: 1.0000\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1879 - acc: 1.0000\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1868 - acc: 1.0000\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1858 - acc: 1.0000\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1848 - acc: 1.0000\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1837 - acc: 1.0000\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1827 - acc: 1.0000\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1817 - acc: 1.0000\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1807 - acc: 1.0000\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1797 - acc: 1.0000\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1787 - acc: 1.0000\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1777 - acc: 1.0000\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1767 - acc: 1.0000\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1758 - acc: 1.0000\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1748 - acc: 1.0000\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.1739 - acc: 1.0000\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1729 - acc: 1.0000\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1720 - acc: 1.0000\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1710 - acc: 1.0000\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1701 - acc: 1.0000\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1692 - acc: 1.0000\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1683 - acc: 1.0000\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1674 - acc: 1.0000\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1665 - acc: 1.0000\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1656 - acc: 1.0000\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1648 - acc: 1.0000\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1639 - acc: 1.0000\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1630 - acc: 1.0000\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1622 - acc: 1.0000\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1613 - acc: 1.0000\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1605 - acc: 1.0000\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1597 - acc: 1.0000\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1588 - acc: 1.0000\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1580 - acc: 1.0000\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1572 - acc: 1.0000\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1564 - acc: 1.0000\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1556 - acc: 1.0000\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1548 - acc: 1.0000\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1540 - acc: 1.0000\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1532 - acc: 1.0000\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1524 - acc: 1.0000\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1517 - acc: 1.0000\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1509 - acc: 1.0000\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1501 - acc: 1.0000\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1494 - acc: 1.0000\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1486 - acc: 1.0000\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1479 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec9c51e790>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kA6R4PmS8XW",
        "outputId": "8c7dfb58-dff3-4910-e8b8-9847436ea49c"
      },
      "source": [
        "# 예측\n",
        "pred = model.predict(X)\n",
        "print(\"pred : \\n\", pred)\n",
        "print(\"=\"*100)\n",
        "\n",
        "predict01 = np.where(pred > 0.5, 1, 0)\n",
        "print(\"0.5보다 크면 1, 아니면 0 :\\n\",predict01)\n",
        "print(\"=\"*100)\n",
        "\n",
        "predict02 = predict01.flatten()\n",
        "print(\"1차원 배열로 변환 : \",predict02)\n",
        "print(\"=\"*100)\n",
        "\n",
        "predict03 = (predict02 == y)\n",
        "print(\"맞으면 True, 틀리면 False :\", predict03)\n",
        "\n",
        "# 정확도 계산\n",
        "acc =np.sum(predict03)/len(predict03)\n",
        "print(\"정확도 :\",acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred : \n",
            " [[0.0820266 ]\n",
            " [0.8528396 ]\n",
            " [0.85800016]\n",
            " [0.17367616]]\n",
            "====================================================================================================\n",
            "0.5보다 크면 1, 아니면 0 :\n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "====================================================================================================\n",
            "1차원 배열로 변환 :  [0 1 1 0]\n",
            "====================================================================================================\n",
            "맞으면 True, 틀리면 False : [ True  True  True  True]\n",
            "정확도 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa_TQzpAT0Ox",
        "outputId": "7eaafd9c-6143-4c2a-b670-0f48b0aa5965"
      },
      "source": [
        "# 0,1 xor 연산\n",
        "arr =np.array( [ [0, 1]], dtype =\"float32\")\n",
        "\n",
        "pred = model.predict(arr)\n",
        "\n",
        "print(pred)\n",
        "\n",
        "pred1 = np.where(pred >0.5,1,0)\n",
        "print(\"0 XOR 1 = \",pred1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8528396]]\n",
            "0 XOR 1 =  [[1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CcAxXVfVGud",
        "outputId": "7cd18f78-b196-4423-f718-b2694891276d"
      },
      "source": [
        "# 0,1 xor 연산\n",
        "arr =np.array( [ [1, 1]], dtype =\"float32\")\n",
        "\n",
        "pred = model.predict(arr)\n",
        "\n",
        "print(pred)\n",
        "\n",
        "pred1 = np.where(pred >0.5,1,0)\n",
        "print(\"1 XOR 1 = \",pred1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.17367616]]\n",
            "1 XOR 1 =  [[0]]\n"
          ]
        }
      ]
    }
  ]
}
